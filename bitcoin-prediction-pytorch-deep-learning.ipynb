{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bitcoin-prediction-pytorch-deep-learning.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/sshillo/blog/blob/master/bitcoin-prediction-pytorch-deep-learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"nPhE8g9innF3"},"source":["## Intro\n","It's December 2020 and bitcoin prices have hit an all time high. I've recently gone down a rabbit hole of trying to create a reinforcement learning bot to trade bitcoin. While that task is still a work in progress, I thought it useful to show how to predict bitcoin prices using deep learning. This is a good place to start for most people who want to get into deep learning, reinforcement learning, or automated trading. "]},{"cell_type":"markdown","metadata":{"id":"RzAVjarl0TPq"},"source":["### Why Pytorch aka what libraries and how come?\n","\n","You might be asking yourself why not tensorflow or keras or stable baselines or something pytorch lightning or something else. \n","\n","My main reason for using pytorch is that it's backed by Facebook, and it allows you to write clean pythonic code that is easy to understand. My impressions of tensorflow were that python had been used to create some dsl on top of what was actually happening, which means a steep learning curve because you arn't writing the python code that you are used to.\n","\n","### Why not pytorch lighting or stable baselines 3 or some other library?\n","\n","Well first off, if you're learning new things, start with the least amount of external libraries and add them as needed. Having a library like stable baselines I think is only good, if you've already implemented every algorithm yourself, or you're not going to know what you are doing and why. Out of the box modeling libraries are going to be doing stuff like batch normalization, gradient clipping, and blah blah blah, do you really need this stuff, and/or know what it actually does, in what use cases. In my experience it's better to start with the simplist thing possible, it's not that hard to build a model from scratch, along the way you might find yourself creating a library that ends up looking like one of these others, for complex stuff like this I think that's a good thing, this isn't a web framework, where reinventing the wheel is just a waste of time. When it comes to complex things like deep learning, I think reinventing the wheel can sometimes be a good thing."]},{"cell_type":"markdown","metadata":{"id":"pgGlbwabzjum"},"source":["## Setup\n","First, lets install some libraries. "]},{"cell_type":"code","metadata":{"id":"hzSCSH5ebm-G","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1606934853391,"user_tz":0,"elapsed":48500,"user":{"displayName":"Sean Shillo","photoUrl":"","userId":"16099910609850967585"}},"outputId":"69ddd8c6-95de-41be-86a6-8d3a34c47f72"},"source":["!pip install chart_studio plotly==4.9.0 statsmodels==0.11.0 pmdarima ipdb wandb pyarrow==2.0.0\n","!pip install pytorch-lightning==1.0.4"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting chart_studio\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/ce/330794a6b6ca4b9182c38fc69dd2a9cbff60fd49421cb8648ee5fee352dc/chart_studio-1.1.0-py3-none-any.whl (64kB)\n","\u001b[K     |████████████████████████████████| 71kB 5.3MB/s \n","\u001b[?25hCollecting plotly==4.9.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/5f/47ab0d9d843c5be0f5c5bd891736a4c84fa45c3b0a0ddb6b6df7c098c66f/plotly-4.9.0-py2.py3-none-any.whl (12.9MB)\n","\u001b[K     |████████████████████████████████| 12.9MB 8.5MB/s \n","\u001b[?25hCollecting statsmodels==0.11.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/bf/134d0f9b4fa62b830dcf7ed0567d4964f0a7fae12862ff252748541a4c94/statsmodels-0.11.0-cp36-cp36m-manylinux1_x86_64.whl (8.7MB)\n","\u001b[K     |████████████████████████████████| 8.7MB 32.8MB/s \n","\u001b[?25hCollecting pmdarima\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/62/725b3b6ae0e56c77534de5a8139322e7b863ca53fd5bd6bd3b7de87d0c20/pmdarima-1.7.1-cp36-cp36m-manylinux1_x86_64.whl (1.5MB)\n","\u001b[K     |████████████████████████████████| 1.5MB 48.9MB/s \n","\u001b[?25hCollecting ipdb\n","  Downloading https://files.pythonhosted.org/packages/44/8c/76b33b115f4f2c090e2809a0247fe777eb3832f9d606479bf0139b29ca2c/ipdb-0.13.4.tar.gz\n","Collecting wandb\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/7c/bf3cba8513f02c92fff0f0dab49846f1aa3da93c71fb4de7f34f501d15f0/wandb-0.10.11-py2.py3-none-any.whl (1.8MB)\n","\u001b[K     |████████████████████████████████| 1.8MB 74.8MB/s \n","\u001b[?25hCollecting pyarrow==2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e1/27958a70848f8f7089bff8d6ebe42519daf01f976d28b481e1bfd52c8097/pyarrow-2.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.7MB)\n","\u001b[K     |████████████████████████████████| 17.7MB 386kB/s \n","\u001b[?25hRequirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from chart_studio) (1.3.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from chart_studio) (1.15.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from chart_studio) (2.23.0)\n","Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.6/dist-packages (from statsmodels==0.11.0) (0.5.1)\n","Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels==0.11.0) (1.4.1)\n","Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.6/dist-packages (from statsmodels==0.11.0) (1.1.4)\n","Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from statsmodels==0.11.0) (1.18.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from pmdarima) (0.17.0)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from pmdarima) (1.24.3)\n","Collecting setuptools<50.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/a9/5dc32465951cf4812e9e93b4ad2d314893c2fa6d5f66ce5c057af6e76d85/setuptools-49.6.0-py3-none-any.whl (803kB)\n","\u001b[K     |████████████████████████████████| 808kB 73.9MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.6/dist-packages (from pmdarima) (0.22.2.post1)\n","Collecting Cython<0.29.18,>=0.29\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/d7/510ddef0248f3e1e91f9cc7e31c0f35f8954d0af92c5c3fd4c853e859ebe/Cython-0.29.17-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 61.4MB/s \n","\u001b[?25hRequirement already satisfied: ipython>=5.1.0 in /usr/local/lib/python3.6/dist-packages (from ipdb) (5.5.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n","Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.3)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n","Collecting subprocess32>=3.5.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n","\u001b[K     |████████████████████████████████| 102kB 13.1MB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.12.4)\n","Collecting shortuuid>=0.5.0\n","  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n","Collecting sentry-sdk>=0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/e1/3a9f8ca1009fc6a1e850801f2386e9d88b95147218cbe8c33bc4d60b3695/sentry_sdk-0.19.4-py2.py3-none-any.whl (128kB)\n","\u001b[K     |████████████████████████████████| 133kB 58.0MB/s \n","\u001b[?25hCollecting configparser>=3.8.1\n","  Downloading https://files.pythonhosted.org/packages/08/b2/ef713e0e67f6e7ec7d59aea3ee78d05b39c15930057e724cc6d362a8c3bb/configparser-5.0.1-py3-none-any.whl\n","Collecting GitPython>=1.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/d1/a7f8fe3df258549b303415157328bfcc63e9b11d06a7ad7a3327f3d32606/GitPython-3.1.11-py3-none-any.whl (159kB)\n","\u001b[K     |████████████████████████████████| 163kB 64.1MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n","Collecting watchdog>=0.8.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/10/500580a0987363a0d9e1f3dd5cb1bba94a47e19266c6ce9dfb6cdd455758/watchdog-0.10.4.tar.gz (98kB)\n","\u001b[K     |████████████████████████████████| 102kB 4.7MB/s \n","\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->chart_studio) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->chart_studio) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->chart_studio) (2020.11.8)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->statsmodels==0.11.0) (2018.9)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (1.0.18)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (0.8.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (4.4.2)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (4.3.3)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (2.6.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (0.7.5)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (4.8.0)\n","Collecting gitdb<5,>=4.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 11.3MB/s \n","\u001b[?25hCollecting pathtools>=0.1.1\n","  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.1.0->ipdb) (0.2.5)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython>=5.1.0->ipdb) (0.2.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.1.0->ipdb) (0.6.0)\n","Collecting smmap<4,>=3.0.1\n","  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n","Building wheels for collected packages: ipdb, subprocess32, watchdog, pathtools\n","  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ipdb: filename=ipdb-0.13.4-cp36-none-any.whl size=10973 sha256=99773c8c542423b6cf540c820d25b827a0945cea36c454c2e2ee8b1da543f986\n","  Stored in directory: /root/.cache/pip/wheels/56/51/e4/c91c61e3481a1a967beb18c4ea7a2b138a63cce94170b2e206\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=f7f11b92cccbbcc7a88ec65c2dc848940ad45071cbda1197cd86082c202d639a\n","  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n","  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for watchdog: filename=watchdog-0.10.4-cp36-none-any.whl size=74841 sha256=e16849f12ad2739602b78435aecf6cb4aa394eeee85b410dda7b735903b25ae8\n","  Stored in directory: /root/.cache/pip/wheels/9e/11/04/5160b8815b0cc7cf574bdc6d053e510169ec264c8791b4ec3a\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8785 sha256=d3ba9b1c7f5810ecfd49d7b28175823378ea2c06caad7d51ef721d680d4337a8\n","  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n","Successfully built ipdb subprocess32 watchdog pathtools\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","Installing collected packages: plotly, chart-studio, statsmodels, setuptools, Cython, pmdarima, ipdb, docker-pycreds, subprocess32, shortuuid, sentry-sdk, configparser, smmap, gitdb, GitPython, pathtools, watchdog, wandb, pyarrow\n","  Found existing installation: plotly 4.4.1\n","    Uninstalling plotly-4.4.1:\n","      Successfully uninstalled plotly-4.4.1\n","  Found existing installation: statsmodels 0.10.2\n","    Uninstalling statsmodels-0.10.2:\n","      Successfully uninstalled statsmodels-0.10.2\n","  Found existing installation: setuptools 50.3.2\n","    Uninstalling setuptools-50.3.2:\n","      Successfully uninstalled setuptools-50.3.2\n","  Found existing installation: Cython 0.29.21\n","    Uninstalling Cython-0.29.21:\n","      Successfully uninstalled Cython-0.29.21\n","  Found existing installation: pyarrow 0.14.1\n","    Uninstalling pyarrow-0.14.1:\n","      Successfully uninstalled pyarrow-0.14.1\n","Successfully installed Cython-0.29.17 GitPython-3.1.11 chart-studio-1.1.0 configparser-5.0.1 docker-pycreds-0.4.0 gitdb-4.0.5 ipdb-0.13.4 pathtools-0.1.2 plotly-4.9.0 pmdarima-1.7.1 pyarrow-2.0.0 sentry-sdk-0.19.4 setuptools-49.6.0 shortuuid-1.0.1 smmap-3.0.4 statsmodels-0.11.0 subprocess32-3.5.4 wandb-0.10.11 watchdog-0.10.4\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pkg_resources"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["Collecting pytorch-lightning==1.0.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/e7/d9ac82471c6a6246963726a62dfbd858b81ad63de71ed9dd18fc491596c4/pytorch_lightning-1.0.4-py3-none-any.whl (554kB)\n","\u001b[K     |████████████████████████████████| 563kB 8.7MB/s \n","\u001b[?25hCollecting fsspec>=0.8.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/8b/1df260f860f17cb08698170153ef7db672c497c1840dcc8613ce26a8a005/fsspec-0.8.4-py3-none-any.whl (91kB)\n","\u001b[K     |████████████████████████████████| 92kB 9.1MB/s \n","\u001b[?25hCollecting future>=0.17.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n","\u001b[K     |████████████████████████████████| 829kB 13.3MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==1.0.4) (2.3.0)\n","Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==1.0.4) (1.7.0+cu101)\n","Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==1.0.4) (1.18.5)\n","Collecting PyYAML>=5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n","\u001b[K     |████████████████████████████████| 276kB 22.5MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==1.0.4) (4.41.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.4) (49.6.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.4) (1.33.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.4) (1.7.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.4) (2.23.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.4) (3.3.3)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.4) (0.10.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.4) (1.17.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.4) (1.0.1)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.4) (3.12.4)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.4) (1.15.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.4) (0.35.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.4) (0.4.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.3->pytorch-lightning==1.0.4) (3.7.4.3)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.3->pytorch-lightning==1.0.4) (0.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.0.4) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.0.4) (2020.11.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.0.4) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.0.4) (3.0.4)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.0.4) (2.0.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.0.4) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.0.4) (4.1.1)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.0.4) (4.6)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.0.4) (1.3.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.0.4) (3.4.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.0.4) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.0.4) (3.1.0)\n","Building wheels for collected packages: future, PyYAML\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=491057 sha256=eebaff0ce63452ba7e09f7c653375ff645139d87d537be90b2b9fc4675cc8816\n","  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n","  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44619 sha256=8f7a061cafa8df199213c43ed4024c175e164a779f1dca9c88d2d6eeb406475f\n","  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n","Successfully built future PyYAML\n","Installing collected packages: fsspec, future, PyYAML, pytorch-lightning\n","  Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed PyYAML-5.3.1 fsspec-0.8.4 future-0.18.2 pytorch-lightning-1.0.4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ntrfcbTSnuYg"},"source":["Now let's import everything we need\n"]},{"cell_type":"code","metadata":{"id":"vJ2wQO_tbOeZ","executionInfo":{"status":"ok","timestamp":1606937367559,"user_tz":0,"elapsed":1191,"user":{"displayName":"Sean Shillo","photoUrl":"","userId":"16099910609850967585"}}},"source":["import numpy as np\n","import pandas as pd\n","import plotly.graph_objects as go\n","import os\n","import torch.nn as nn\n","import torch\n","from torch.autograd import Variable\n","import ipdb\n","from torch.utils.data import TensorDataset, DataLoader, Dataset\n","device = torch.device(\"cuda:0\")\n","from sklearn.metrics import mean_squared_error\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","import shutil\n","from IPython.display import clear_output \n","import time\n","import urllib\n","import pmdarima as pm"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OCnsi4Zqn83-"},"source":["### Get the Data\n","I've separately collected 3 years bitcoin data at 15 minute intervals from the binance api. It is stored in parquet because it loads faster and preserves type information."]},{"cell_type":"code","metadata":{"id":"FBaBV1EfO17U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606937313185,"user_tz":0,"elapsed":3451,"user":{"displayName":"Sean Shillo","photoUrl":"","userId":"16099910609850967585"}},"outputId":"41dd706f-3071-4f3d-9910-07a0ea26f20f"},"source":["bitcoin_data_url = \"https://drive.google.com/u/0/uc?id=14iEVdVtBaVfN6dMg0bO4QrfSaUoeXJ4Y&export=download\"\n","urllib.request.urlretrieve(bitcoin_data_url, \"data.parquet\")"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('data.parquet', <http.client.HTTPMessage at 0x7f9fffdd0908>)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"oS0koIBz4vDX"},"source":["### Creating a Baseline\n","\n","Before we predict bitcoin prices using the new hotness, we need to set a baseline. I've read many blogs telling me how to do something similar to this, and each time I ask myself why? Well the answer should be better performance, if we can predict prices using something that already works and is less complex, we should do that. The gold standard for predicting timeseries data are arima models, so we're going to use that. For more info on arima, please go [here](https://www.machinelearningplus.com/time-series/arima-model-time-series-forecasting-python/#:~:text=So%20what%20exactly%20is%20an,used%20to%20forecast%20future%20values.)."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dVMZEx5u7Be_","executionInfo":{"status":"ok","timestamp":1606937561024,"user_tz":0,"elapsed":2812,"user":{"displayName":"Sean Shillo","photoUrl":"","userId":"16099910609850967585"}},"outputId":"e02f38da-13c3-4cee-ec4f-b3c504df357d"},"source":["df = pd.read_parquet('data.parquet')\n","data = df['close']\n","train, test = train_test_split(data, train_size=80)\n","\n","# Fit a simple auto_arima model\n","modl = pm.auto_arima(train, start_p=1, start_q=1, start_P=1, start_Q=1,\n","                     max_p=5, max_q=5, max_P=5, max_Q=5, seasonal=True,\n","                     stepwise=True, suppress_warnings=True, D=10, max_D=10,\n","                     error_action='ignore')\n","\n","print(modl)\n","\n","# Create predictions for the future, evaluate on test\n","preds, conf_int = modl.predict(n_periods=test.shape[0], return_conf_int=True)\n","\n","# Print the error:\n","print(\"Test RMSE: %.3f\" % np.sqrt(mean_squared_error(test, preds)))"],"execution_count":13,"outputs":[{"output_type":"stream","text":[" ARIMA(0,0,0)(0,0,0)[0] intercept\n","Test RMSE: 2694.857\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"txrHZym48c0D"},"source":["So what happened here? \n","First we split the data into  I'm using a library called pmarima, to \n","\n","*   We split the data into train / test\n","*   I fitted a model using the pmarima library which finds the best hyperparaters for our arima model\n","* Lastly we computed the RMSE(root mean squared error) on the test data test, we'll compare these predictions and RSME to our pytorch model\n"]},{"cell_type":"markdown","metadata":{"id":"xm8Yn9OdoT1m"},"source":["Now lets create the Model. I'm using GRU instead of LSTM, because it's a little simpler in implementation"]},{"cell_type":"code","metadata":{"id":"e8zOffAPWBbp"},"source":["class GRU(nn.Module):\n","    def __init__(self, i_size, h_size, n_layers, o_size):\n","        super(GRU, self).__init__()\n","\n","        self.rnn = nn.GRU(\n","            input_size=i_size,\n","            hidden_size=h_size,\n","            num_layers=n_layers,\n","            batch_first=True\n","        )\n","        self.hidden_size = h_size\n","        self.num_layers = n_layers\n","        self.out = nn.Linear(h_size, o_size)\n","\n","    def init_hidden(self, batch_size=32):\n","      return torch.zeros(self.num_layers, batch_size, self.hidden_size)\n","\n","    def forward(self, x, hidden=None):\n","        #num layers, batch size, hidden\n","        if hidden is None:\n","          batch_size = x.shape[0]\n","          hidden = self.init_hidden(batch_size)\n","          hidden = hidden.type_as(x)\n","\n","        out, next_hidden = self.rnn(x, hidden)\n","        outs = self.out(out[:,-1,:])\n","\n","        return outs, next_hidden \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YfqDcui4oplg"},"source":["I'm going to create a function because functions are nice, they're reusable, if you want to transfer this code out of jupyter, it makes life a lot easier. Actually if I weren't writing a blog post, I would keep most of my code outside of the ipynb file, just importing the functions I need, and merely using the notebook as a way to display graphs inline. There's more to this tangent, but I'll leave that for another blog post."]},{"cell_type":"code","metadata":{"id":"_ynC2D16odW9"},"source":["def run(model_klass, \n","        dataset_train, \n","        dataset_test, \n","        sc, \n","        name='test',\n","        input_size =15,\n","        hidden_size=64,\n","        num_layers=2,\n","        output_size=1,\n","        num_epochs=3, \n","        batch_size=32,\n","        learning_rate=.001):\n","  print(f\"RUNNING {name}\")\n","  training_set = dataset_train\n","  training_set_scaled = sc.fit_transform(training_set)\n","\n","  X_train = []\n","  y_train = []\n","  for i in range(input_size, training_set_scaled.shape[0]):\n","      X_train.append(training_set_scaled[i-input_size:i, 0])\n","      y_train.append(training_set_scaled[i, 0])\n","  X_train, y_train = np.array(X_train), np.array(y_train)\n","\n","  X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n","\n","  rnn = model_klass(input_size, hidden_size, num_layers, output_size).to(device)\n","\n","  optimiser = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n","  criterion = nn.MSELoss()\n","\n","  inputs = Variable(torch.from_numpy(X_train).float()).to(device)\n","  labels = Variable(torch.from_numpy(y_train).float()).to(device)\n","\n","  dataset = TensorDataset(inputs, labels)\n","  loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n","  for epoch in range(num_epochs):\n","      losses = []\n","      hidden = rnn.init_hidden(batch_size=batch_size).to(device)\n","      for inputs, labels in loader:\n","        hidden = hidden.data\n","        output, hidden = rnn(inputs, None) \n","\n","        optimiser.zero_grad()\n","        loss = criterion(output.view(-1), labels)\n","        loss.backward()                     # back propagation\n","        optimiser.step()                                     # update the parameters\n","        losses.append(loss.item())\n","      if epoch % 5 == 0:\n","        print('epoch {}, loss {}'.format(epoch,np.mean(losses)))\n","\n","  real_stock_price = dataset_test #open values\n","  # Getting the predicted stock price of 2017\n","  dataset_total = np.concatenate((dataset_train, dataset_test), axis = 0)\n","  # inputs = dataset_total[len(dataset_total) - len(dataset_test) - INPUT_SIZE:].values\n","  inputs = dataset_total\n","  inputs = inputs.reshape(-1,1)\n","  # inputs = np.diff(inputs, axis=0)\n","  inputs = sc.transform(inputs)\n","  X_test = []\n","  for i in range(input_size, len(inputs)):\n","      X_test.append(inputs[i-input_size:i, 0])\n","  X_test = np.array(X_test)\n","  X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n","\n","  # X_train_X_test = np.concatenate((X_train, X_test),axis=0)\n","  test_inputs = Variable(torch.from_numpy(X_test).float()).to(device)\n","  # test_inputs = Variable(torch.from_numpy(X_train_X_test).float()).to(dev)\n","  predicted_stock_price, b = rnn(test_inputs)\n","  predicted_stock_price = np.reshape(predicted_stock_price.detach().cpu().numpy(), (test_inputs.cpu().shape[0], 1))\n","\n","  predicted_stock_price = sc.inverse_transform(predicted_stock_price)[:,0]\n","  # predicted_stock_price = diffinv(predicted_stock_price, start).reshape(-1, 1)\n","\n","  real_stock_price_all = dataset_total[input_size:][:,0]\n","\n","  # Visualising the results\n","  N = predicted_stock_price.shape[0]\n","  test_start = int(N * 0.75)\n","\n","  fig = go.Figure()\n","  fig.add_trace(go.Scatter(y=real_stock_price_all, name='Real'))\n","  fig.add_trace(go.Scatter(y=predicted_stock_price, name='Pred'))\n","  fig.add_shape(type=\"line\",\n","    x0=test_start, y0=0, x1=test_start, y1=20000,\n","    line=dict(color=\"RoyalBlue\",width=1))\n","  fig.add_trace(go.Scatter(\n","      x=[test_start - 5000], y=[15000],\n","      text=[\"Train/Test Split\"],\n","      mode=\"text\",\n","  ))\n","  fig.show()\n","\n","  # mean_squared_error(real_stock_price_all, predicted_stock_price, squared=False)\n","  t_d = predicted_stock_price[test_start:]\n","  r_d = real_stock_price_all[test_start:]\n","  test_rse = mean_squared_error(t_d, r_d, squared=False)\n","\n","  t_d = predicted_stock_price[0:test_start]\n","  r_d = real_stock_price_all[0:test_start]\n","  train_rse = mean_squared_error(t_d, r_d, squared=False)\n","  return name, train_rse, test_rse"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NPjeY666paw7"},"source":["Ok, now everything is setup, we're going to run everything"]},{"cell_type":"code","metadata":{"id":"QlYMXPINpZJk"},"source":["start = time.time()\n","\n","df = pd.read_parquet('./data.parquet')\n","cols = ['open']\n","data_train, data_test = train_test_split(df[cols].values, test_size=0.25, shuffle=False)\n","\n","errors = []\n","\n","sc = MinMaxScaler(feature_range = (-1, 1))\n","err = run(GRU, data_train, data_test, sc, 'gru minmax 0,1')\n","errors.append(err)\n","\n","total_time = time.time() - start\n","print(\"Total time:\", total_time)\n","\n","df = pd.DataFrame(errors)\n","df.columns = ['name','train error', 'test error']\n","print(df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JF0AX9YZpuft"},"source":["From the graph we can see that the model does a good, job predicting the price in just a few epochs."]}]}